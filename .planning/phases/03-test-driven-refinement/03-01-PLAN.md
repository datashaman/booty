---
phase: 03-test-driven-refinement
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - pyproject.toml
  - src/booty/test_runner/__init__.py
  - src/booty/test_runner/config.py
  - src/booty/test_runner/executor.py
  - src/booty/test_runner/parser.py
autonomous: true

must_haves:
  truths:
    - "System loads and validates .booty.yml config from target repo workspace"
    - "System executes test commands in subprocess with configurable timeout"
    - "System captures exit code, stdout, stderr from test execution"
    - "Timed-out processes are killed and cleaned up (no zombies)"
    - "System extracts file paths and error summaries from test output"
  artifacts:
    - path: "src/booty/test_runner/config.py"
      provides: "BootyConfig Pydantic model and load_booty_config function"
      contains: "class BootyConfig"
    - path: "src/booty/test_runner/executor.py"
      provides: "TestResult dataclass and execute_tests async function"
      contains: "async def execute_tests"
    - path: "src/booty/test_runner/parser.py"
      provides: "Error extraction from test output"
      exports: ["extract_error_summary", "extract_files_from_output"]
    - path: "pyproject.toml"
      provides: "PyYAML and tenacity dependencies"
      contains: "pyyaml"
  key_links:
    - from: "src/booty/test_runner/config.py"
      to: "pydantic.BaseModel"
      via: "Pydantic validation of YAML config"
      pattern: "BaseModel"
    - from: "src/booty/test_runner/executor.py"
      to: "asyncio.create_subprocess_shell"
      via: "Async subprocess with wait_for timeout"
      pattern: "create_subprocess_shell"
---

<objective>
Create the test runner module: .booty.yml config loading, async subprocess test execution with timeout, and test output parsing for error extraction.

Purpose: Foundation for iterative refinement — the system needs to run tests and understand their output before it can retry code generation.
Output: `src/booty/test_runner/` module with config, executor, and parser components.
</objective>

<execution_context>
@/Users/marlinf/.claude/get-shit-done/workflows/execute-plan.md
@/Users/marlinf/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/03-test-driven-refinement/03-RESEARCH.md

@pyproject.toml
@src/booty/config.py
@src/booty/logging.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Add dependencies and create test_runner config module</name>
  <files>pyproject.toml, src/booty/test_runner/__init__.py, src/booty/test_runner/config.py</files>
  <action>
    1. Add `pyyaml` and `tenacity` to the `dependencies` list in `pyproject.toml`.

    2. Create `src/booty/test_runner/__init__.py` — empty init file.

    3. Create `src/booty/test_runner/config.py` with:
       - `BootyConfig(BaseModel)` Pydantic model with:
         - `test_command: str` — required, validated non-empty
         - `timeout: int = 300` — min 10, max 3600 (seconds)
         - `max_retries: int = 3` — min 1, max 10
       - `load_booty_config(workspace_path: Path) -> BootyConfig` function:
         - Looks for `.booty.yml` in workspace root
         - Raises `FileNotFoundError` with helpful message if missing (including example config)
         - Raises `ValueError` if YAML is empty
         - Uses `yaml.safe_load()` for parsing
         - Uses `BootyConfig.model_validate()` for validation
       - Use `field_validator` to strip and validate `test_command` is not blank

    Use existing patterns: Pydantic BaseModel (like `src/booty/llm/models.py`), structlog logger from `booty.logging`.
  </action>
  <verify>
    - `python -c "from booty.test_runner.config import BootyConfig, load_booty_config; print('OK')"` succeeds
    - `python -c "from booty.test_runner.config import BootyConfig; c = BootyConfig(test_command='pytest'); print(c.timeout, c.max_retries)"` prints `300 3`
  </verify>
  <done>BootyConfig validates .booty.yml schema, load_booty_config reads YAML from workspace path, missing config raises clear FileNotFoundError</done>
</task>

<task type="auto">
  <name>Task 2: Create test executor and output parser</name>
  <files>src/booty/test_runner/executor.py, src/booty/test_runner/parser.py</files>
  <action>
    1. Create `src/booty/test_runner/executor.py` with:
       - `TestResult` dataclass with fields: `exit_code: int`, `stdout: str`, `stderr: str`, `timed_out: bool = False`
       - `async def execute_tests(command: str, timeout: int, workspace_path: Path) -> TestResult`:
         - Uses `asyncio.create_subprocess_shell()` with `stdout=PIPE, stderr=PIPE, cwd=str(workspace_path)`
         - Wraps `proc.communicate()` in `asyncio.wait_for(timeout=timeout)`
         - On timeout: `proc.kill()` then `await proc.wait()` (prevent zombies), returns TestResult with `timed_out=True`, exit_code=-1
         - On any other exception: returns TestResult with exit_code=-1 and error in stderr
         - Decodes stdout/stderr with `errors='replace'` to handle non-UTF-8 output
         - Logs: test start, timeout kill, execution error, completion with exit code
       - Use structlog logger from `booty.logging`

    2. Create `src/booty/test_runner/parser.py` with:
       - `extract_error_summary(stderr: str, stdout: str, max_lines: int = 100) -> str`:
         - Combines stderr + stdout
         - Keeps lines matching: traceback headers, `File "..."` lines, traceback continuation lines, `AssertionError`/`assert` lines, `FAILED `/ `ERROR ` prefix lines, lines with 'failed'/'error'
         - Truncates to `max_lines` with truncation notice
       - `extract_files_from_output(output: str, workspace_path: Path) -> set[str]`:
         - Parses `File "/path/to/file.py", line N` patterns
         - Converts to workspace-relative paths using `file_path.relative_to(workspace_path)`
         - Excludes files outside workspace (ValueError from relative_to)
         - Excludes test files (any path part starting with 'test')
         - Returns set of workspace-relative path strings

    Follow research patterns from 03-RESEARCH.md exactly. No imports of external libraries beyond stdlib + booty.logging.
  </action>
  <verify>
    - `python -c "from booty.test_runner.executor import TestResult, execute_tests; print('OK')"` succeeds
    - `python -c "from booty.test_runner.parser import extract_error_summary, extract_files_from_output; print('OK')"` succeeds
    - `python -c "from booty.test_runner.executor import TestResult; r = TestResult(exit_code=0, stdout='ok', stderr=''); print(r.timed_out)"` prints `False`
  </verify>
  <done>execute_tests runs subprocess with timeout and returns structured TestResult; parser extracts error summaries and file paths from test output</done>
</task>

</tasks>

<verification>
- All imports work: `python -c "from booty.test_runner.config import BootyConfig, load_booty_config; from booty.test_runner.executor import TestResult, execute_tests; from booty.test_runner.parser import extract_error_summary, extract_files_from_output; print('All imports OK')"`
- `pip install -e .` succeeds (new dependencies resolve)
- BootyConfig validates correctly: required test_command, optional timeout/max_retries with bounds
- TestResult is a proper dataclass with expected fields
- No circular imports between test_runner submodules
</verification>

<success_criteria>
- `src/booty/test_runner/` module exists with config.py, executor.py, parser.py
- PyYAML and tenacity added to pyproject.toml dependencies
- BootyConfig loads and validates .booty.yml with clear error on missing file
- execute_tests runs async subprocess with timeout, kills on timeout, no zombie processes
- Parser extracts error summaries and identifies failing file paths from test output
</success_criteria>

<output>
After completion, create `.planning/phases/03-test-driven-refinement/03-01-SUMMARY.md`
</output>
