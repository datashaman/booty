---
phase: 02-llm-code-generation
plan: 05
type: execute
wave: 3
depends_on: ["02-01", "02-02", "02-03", "02-04"]
files_modified:
  - src/booty/code_gen/generator.py
  - src/booty/main.py
autonomous: true

must_haves:
  truths:
    - "process_job() orchestrates the full pipeline: analyze -> budget check -> generate -> validate -> commit -> push -> PR"
    - "Issue analysis produces structured understanding before code generation"
    - "Generated code is validated (syntax + path security) before commit"
    - "PR appears on GitHub with conventional commit, structured description, and issue reference"
    - "Context overflow is detected and handled gracefully (no silent failures)"
    - "Multi-file changes are committed atomically"
  artifacts:
    - path: "src/booty/code_gen/generator.py"
      provides: "Main orchestrator function for issue-to-PR pipeline"
      exports: ["process_issue_to_pr"]
      min_lines: 60
    - path: "src/booty/main.py"
      provides: "Updated process_job wiring to generator"
      contains: "process_issue_to_pr"
  key_links:
    - from: "src/booty/code_gen/generator.py"
      to: "src/booty/llm/prompts.py"
      via: "analyze_issue and generate_code_changes calls"
      pattern: "analyze_issue|generate_code_changes"
    - from: "src/booty/code_gen/generator.py"
      to: "src/booty/code_gen/security.py"
      via: "PathRestrictor.validate_all_paths"
      pattern: "validate_all_paths|is_path_allowed"
    - from: "src/booty/code_gen/generator.py"
      to: "src/booty/code_gen/validator.py"
      via: "validate_generated_code for each file"
      pattern: "validate_generated_code"
    - from: "src/booty/code_gen/generator.py"
      to: "src/booty/git/operations.py"
      via: "commit_changes and push_to_remote"
      pattern: "commit_changes|push_to_remote"
    - from: "src/booty/code_gen/generator.py"
      to: "src/booty/github/pulls.py"
      via: "create_pull_request"
      pattern: "create_pull_request"
    - from: "src/booty/main.py"
      to: "src/booty/code_gen/generator.py"
      via: "process_job calls process_issue_to_pr"
      pattern: "process_issue_to_pr"
---

<objective>
Wire all Phase 2 components into the main orchestrator: analyze issue, check budget, generate code, validate, commit, push, create PR.

Purpose: This is the integration plan that connects all Phase 2 modules into the end-to-end issue-to-PR pipeline.
Output: Working process_issue_to_pr function called from process_job in main.py.
</objective>

<execution_context>
@/Users/marlinf/.claude/get-shit-done/workflows/execute-plan.md
@/Users/marlinf/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/phases/02-llm-code-generation/02-RESEARCH.md
@.planning/phases/02-llm-code-generation/02-01-SUMMARY.md
@.planning/phases/02-llm-code-generation/02-02-SUMMARY.md
@.planning/phases/02-llm-code-generation/02-03-SUMMARY.md
@.planning/phases/02-llm-code-generation/02-04-SUMMARY.md
@src/booty/main.py
@src/booty/repositories.py
@src/booty/jobs.py
@src/booty/config.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Main code generation orchestrator</name>
  <files>src/booty/code_gen/generator.py</files>
  <action>
  Create src/booty/code_gen/generator.py with the main orchestration function:

  **async def process_issue_to_pr(job: Job, workspace: Workspace, settings: Settings) -> int:**

  The function implements this pipeline:

  1. **List repo files** — Walk workspace.path to get all file paths (relative to root). Exclude .git directory. Sort for determinism.

  2. **Analyze issue** — Call analyze_issue() with:
     - job.payload["issue"]["title"] and job.payload["issue"]["body"]
     - Newline-joined repo file list
     - Model built from settings (LLM_MODEL, LLM_TEMPERATURE, LLM_MAX_TOKENS)
     - Log the analysis result

  3. **Check file count** — If len(files_to_modify + files_to_create) > settings.MAX_FILES_PER_ISSUE, raise ValueError("Issue requires too many file changes")

  4. **Path security check** — Create PathRestrictor.from_config(workspace_root, settings.RESTRICTED_PATHS). Validate all paths from analysis (files_to_modify + files_to_create + files_to_delete).

  5. **Load existing file contents** — Read content of files_to_modify from workspace. Build dict[str, str] of path -> content.

  6. **Token budget check** — Create TokenBudget(settings.LLM_MODEL, settings.LLM_MAX_CONTEXT_TOKENS, settings.LLM_MAX_TOKENS). Check if analysis summary + file contents fits. If not, use select_files_within_budget to trim. If even base content doesn't fit, raise ValueError("Context too large").

  7. **Generate code** — Call generate_code_changes() with analysis summary, selected file contents, issue title/body, model from settings. Returns CodeGenerationPlan.

  8. **Validate generated code** — For each FileChange in plan.changes:
     - Skip if operation == "delete"
     - Call validate_generated_code(Path(change.path), change.content, Path(workspace.path))

  9. **Apply changes to workspace** — For each FileChange:
     - If create/modify: write content to workspace.path / change.path (create parent dirs)
     - If delete: remove file from workspace

  10. **Commit** — Call commit_changes(workspace.repo, file_paths, formatted_commit_message).
      Use format_commit_message with analysis.commit_type, analysis.commit_scope, analysis.summary, plan.approach, job.issue_number.
      Pass deleted paths separately.

  11. **Push** — Call await push_to_remote(workspace.repo, settings.GITHUB_TOKEN)

  12. **Create PR** — Call create_pull_request with:
      - settings.GITHUB_TOKEN, settings.TARGET_REPO_URL
      - workspace.branch (head), settings.TARGET_BRANCH (base)
      - Title: f"{analysis.commit_type}: {analysis.summary}" (or with scope)
      - Body: format_pr_body with plan.approach, changes as dicts, plan.testing_notes, job.issue_number

  13. **Return PR number**

  Log at each major step with structlog. Wrap entire function in try/except to log failures with full context.

  Imports:
  - from pathlib import Path
  - from booty.config import Settings
  - from booty.jobs import Job
  - from booty.repositories import Workspace
  - from booty.llm.prompts import analyze_issue, generate_code_changes, get_llm_model
  - from booty.llm.token_budget import TokenBudget
  - from booty.code_gen.security import PathRestrictor
  - from booty.code_gen.validator import validate_generated_code
  - from booty.git.operations import commit_changes, push_to_remote, format_commit_message
  - from booty.github.pulls import create_pull_request, format_pr_body
  - from booty.logging import get_logger
  </action>
  <verify>
  Run: `python -c "from booty.code_gen.generator import process_issue_to_pr; print('OK')"`
  Verify all imports resolve without errors.
  </verify>
  <done>process_issue_to_pr orchestrates the full pipeline: analyze -> budget -> generate -> validate -> commit -> push -> PR. All Phase 2 modules connected.</done>
</task>

<task type="auto">
  <name>Task 2: Wire orchestrator into process_job</name>
  <files>src/booty/main.py</files>
  <action>
  Update src/booty/main.py to call the orchestrator:

  1. Add import: `from booty.code_gen.generator import process_issue_to_pr`

  2. Replace the process_job function body. Keep the workspace context manager. Inside it, replace the "Phase 2 will add LLM code generation here" comment with:

  ```python
  pr_number = await process_issue_to_pr(job, workspace, settings)
  logger.info("pr_created", pr_number=pr_number)
  ```

  3. Keep existing logging (job_started, workspace_ready, job_completed).

  Do NOT change any other part of main.py (lifespan, app setup, health check, etc.)
  </action>
  <verify>
  Run: `python -c "from booty.main import app, process_job; print('OK')"`
  Verify the import chain works (main -> generator -> all modules).
  </verify>
  <done>process_job now calls process_issue_to_pr inside workspace context. Full pipeline wired: webhook -> job queue -> process_job -> analyze -> generate -> validate -> commit -> push -> PR.</done>
</task>

</tasks>

<verification>
- [ ] `python -c "from booty.code_gen.generator import process_issue_to_pr"` succeeds
- [ ] `python -c "from booty.main import app"` succeeds (full import chain)
- [ ] generator.py imports all Phase 2 modules without circular dependencies
- [ ] Pipeline steps are logged with structlog at each major step
- [ ] File count limit checked before generation
- [ ] Path security checked before generation
- [ ] Token budget checked before generation
- [ ] Code validated after generation, before commit
- [ ] Deleted files handled correctly (remove, not add)
- [ ] PR body includes changes table, testing notes, issue reference
</verification>

<success_criteria>
End-to-end pipeline complete. A webhook event triggers job processing, which analyzes the issue, generates code, validates it, commits to a feature branch, pushes, and creates a PR on GitHub. All Phase 2 success criteria met:
1. Structured issue analysis (REQ-07)
2. Syntactically valid code generation (REQ-08)
3. Multi-file coordinated changes (REQ-11)
4. PR with conventional commit, description, issue ref (REQ-10)
5. Token budget enforcement (REQ-09)
6. Path restriction enforcement (REQ-15)
</success_criteria>

<output>
After completion, create `.planning/phases/02-llm-code-generation/02-05-SUMMARY.md`
</output>
