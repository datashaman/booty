---
phase: 10-import-compile-detection
plan: 02
type: execute
wave: 1
depends_on: []
files_modified:
  - src/booty/verifier/imports.py
autonomous: true

must_haves:
  truths:
    - "Verifier can compile-sweep changed .py files and capture SyntaxError with path:line"
    - "Verifier can validate imports resolve in workspace (subprocess in workspace env)"
    - "Failures produce annotation dicts (path, start_line, annotation_level, message, title)"
  artifacts:
    - path: src/booty/verifier/imports.py
      provides: compile_sweep, validate_imports, format for check output
      contains: "compile_sweep|validate_imports"
  key_links:
    - from: verifier/imports.py
      to: ast, py_compile
      via: stdlib
      pattern: "import ast|import py_compile"
---

<objective>
Create verifier/imports.py with compile sweep, import validation, and annotation formatting. No runner wiring yet — pure logic module consumed by Plan 03.

Purpose: VERIFY-11 (import resolution), VERIFY-12 (compile failure). RESEARCH: use ast, py_compile, subprocess for import validation.
Output: verifier/imports.py with documented public API.
</objective>

<execution_context>
@/Users/marlinf/.claude/get-shit-done/workflows/execute-plan.md
@/Users/marlinf/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/phases/10-import-compile-detection/10-RESEARCH.md
@.planning/phases/10-import-compile-detection/10-CONTEXT.md
@src/booty/test_generation/validator.py
@src/booty/verifier/limits.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Implement compile_sweep</name>
  <files>src/booty/verifier/imports.py</files>
  <action>
Implement compile_sweep(file_paths: list[Path], workspace_root: Path) -> list[dict]:

1. For each path in file_paths (must be .py; skip .pyi per CONTEXT):
   - full_path = workspace_root / path if path is relative else Path(path)
   - if not full_path.exists(): skip
   - Use py_compile.compile(str(full_path), doraise=True)
   - On PyCompileError: extract path, line (from exc_value.lineno or 0), msg; append annotation dict

2. Return list of annotation dicts. Each: {"path": str (relative to repo root), "start_line": int, "end_line": int, "annotation_level": "failure", "title": "Syntax error", "message": str}

3. path in annotation: use filename relative to workspace_root for GitHub (e.g. "src/foo/bar.py")
</action>
  <verify>
cd /Users/marlinf/Projects/datashaman/booty && python -c "
from pathlib import Path
from booty.verifier.imports import compile_sweep
# Create temp file with syntax error
import tempfile
with tempfile.NamedTemporaryFile(suffix='.py', delete=False) as f:
    f.write(b'def foo(\\n')  # invalid
    bad = Path(f.name)
try:
    r = compile_sweep([bad.name], Path(bad.parent))
    assert len(r) >= 1
    assert r[0].get('annotation_level') == 'failure'
finally:
    bad.unlink()
print('OK: compile_sweep catches syntax error')
"
  </verify>
  <done>compile_sweep runs py_compile, returns annotation dicts for syntax errors.</done>
</task>

<task type="auto">
  <name>Task 2: Implement validate_imports</name>
  <files>src/booty/verifier/imports.py</files>
  <action>
Implement validate_imports(file_paths: list[Path], workspace_path: Path, timeout: int = 60) -> list[dict]:

1. Run import validation in subprocess IN workspace (same env as tests). Use asyncio.create_subprocess_exec or subprocess.

2. Injected script logic (can be inline python -c or small helper):
   - Add workspace to sys.path so project-internal imports resolve
   - For each path, ast.parse to get imports, then importlib.import_module for each root module
   - Skip TYPE_CHECKING guards: when walking AST, if node is inside `if False:` or `if getattr(typing, 'TYPE_CHECKING', False)` block, skip. Simpler: skip lines inside `if typing.TYPE_CHECKING:` — check ast for If with test matching.
   - Per CONTEXT: validate unconditional imports; conditional only when true at runtime (complex — for MVP validate all unconditional; skip inside `if TYPE_CHECKING`).
   - On ModuleNotFoundError: record path, line (from AST), message

3. Script receives file list via stdin or argv; outputs JSON lines or structured format for parsing.

4. Alternative: run `python -c "import ast; ..."` with file paths as args. Parse each file, collect imports, try import_module. Write results to stdout as JSON.

5. Return list of annotation dicts same format as compile_sweep.
</action>
  <verify>
cd /Users/marlinf/Projects/datashaman/booty && python -c "
from pathlib import Path
from booty.verifier.imports import validate_imports
# Use a file that imports sys (stdlib) — should pass
# Use a file that imports nonexistent — should fail
import tempfile
with tempfile.TemporaryDirectory() as td:
    p = Path(td)
    (p / 't.py').write_text('import definitely_not_a_module_xyz\n')
    r = __import__('asyncio').run(validate_imports([Path('t.py')], p))
    assert len(r) >= 1
    assert 'definitely_not' in str(r[0].get('message', ''))
print('OK: validate_imports catches bad import')
"
  </verify>
  <done>validate_imports runs in workspace subprocess; returns annotation dicts for ModuleNotFoundError.</done>
</task>

<task type="auto">
  <name>Task 3: Parse setup_command stderr and cap annotations</name>
  <files>src/booty/verifier/imports.py</files>
  <action>
Implement parse_setup_stderr(stderr: str, workspace_path: Path) -> list[dict]:

1. Parse patterns: `File "path", line N` and `path:N:` (regex)
2. Extract path (relative to workspace when possible) and line number
3. Return annotation dicts; message from surrounding stderr context
4. If no match: return [] (caller uses check-level summary)

Implement prepare_check_annotations(annotations: list[dict], cap: int = 50) -> tuple[list[dict], bool]:
- Deduplicate by (path, start_line, message)
- If len > cap: truncate to cap, return (truncated, True)
- Return (annotations, truncated)
</action>
  <verify>
cd /Users/marlinf/Projects/datashaman/booty && python -c "
from booty.verifier.imports import parse_setup_stderr, prepare_check_annotations
# parse_setup_stderr
s = 'File \"src/foo.py\", line 10: SyntaxError'
r = parse_setup_stderr(s, __import__('pathlib').Path('.'))
assert len(r) >= 0  # may or may not parse depending on exact format
# prepare_check_annotations
ann = [{'path':'a','start_line':1,'message':'x'}] * 60
out, truncated = prepare_check_annotations(ann, 50)
assert len(out) == 50
assert truncated
print('OK: parse_setup_stderr and prepare_check_annotations')
"
  </verify>
  <done>setup stderr parsed for file:line; annotations capped and deduped.</done>
</task>

</tasks>

<verification>
- compile_sweep returns annotations for SyntaxError
- validate_imports runs in subprocess, catches ModuleNotFoundError
- prepare_check_annotations dedupes and caps at 50
</verification>

<success_criteria>
- verifier/imports.py exists with compile_sweep, validate_imports, parse_setup_stderr, prepare_check_annotations
- Annotation dict format matches GitHub Checks API (path, start_line, end_line, annotation_level, message, title)
- TYPE_CHECKING imports skipped (or documented as MVP simplification)
</success_criteria>

<output>
After completion, create `.planning/phases/10-import-compile-detection/10-02-SUMMARY.md`
</output>
