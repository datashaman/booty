---
phase: 05-test-generation
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - src/booty/test_generation/__init__.py
  - src/booty/test_generation/models.py
  - src/booty/test_generation/detector.py
  - src/booty/test_generation/validator.py
autonomous: true

must_haves:
  truths:
    - "Convention detection identifies primary language from file extensions"
    - "Convention detection finds existing test files and infers naming patterns"
    - "Convention detection parses config files to identify test framework"
    - "Import validator catches hallucinated Python imports using AST parsing"
    - "Import validator allows stdlib, project, and declared dependency imports"
  artifacts:
    - path: "src/booty/test_generation/__init__.py"
      provides: "Module init with public API exports"
      exports: ["detect_conventions", "validate_test_imports", "DetectedConventions"]
    - path: "src/booty/test_generation/models.py"
      provides: "Pydantic model for detected conventions"
      contains: "class DetectedConventions"
    - path: "src/booty/test_generation/detector.py"
      provides: "Convention detection from repo structure"
      exports: ["detect_conventions"]
    - path: "src/booty/test_generation/validator.py"
      provides: "Import validation for generated tests"
      exports: ["validate_test_imports"]
  key_links:
    - from: "src/booty/test_generation/detector.py"
      to: "src/booty/test_generation/models.py"
      via: "returns DetectedConventions"
      pattern: "DetectedConventions"
    - from: "src/booty/test_generation/validator.py"
      to: "ast module"
      via: "AST-based import extraction"
      pattern: "ast\\.parse"
---

<objective>
Build the convention detection and import validation module for language-agnostic test generation.

Purpose: This module detects test conventions (language, framework, directory structure, naming patterns) from target repositories and validates generated test imports to prevent hallucinated packages. It provides the foundation that the LLM prompt integration (Plan 02) builds on.

Output: New `src/booty/test_generation/` module with models, detector, and validator.
</objective>

<execution_context>
@/Users/marlinf/.claude/get-shit-done/workflows/execute-plan.md
@/Users/marlinf/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/05-test-generation/05-RESEARCH.md
@.planning/phases/05-test-generation/05-CONTEXT.md
@src/booty/test_runner/config.py
@src/booty/code_gen/validator.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create DetectedConventions model and convention detector</name>
  <files>
    src/booty/test_generation/__init__.py
    src/booty/test_generation/models.py
    src/booty/test_generation/detector.py
  </files>
  <action>
Create a new `src/booty/test_generation/` module.

**models.py:** Create a Pydantic `DetectedConventions` model with fields:
- `language: str` — primary language ("python", "go", "javascript", "typescript", "rust", "php", "ruby", "java", "cpp", "c", "unknown")
- `test_framework: str | None` — detected framework ("pytest", "unittest", "jest", "vitest", "go test", "cargo test", "phpunit", None)
- `test_directory: str | None` — inferred test directory ("tests", "test", "__tests__", "spec", None)
- `test_file_pattern: str | None` — inferred naming pattern ("test_*.py", "*.test.js", "*_test.go", None)
- `config_file: str | None` — config file path found (as string, not Path — for serialization)
- `existing_test_examples: list[str]` — up to 3 sample test file paths (as strings)

Include a `format_for_prompt()` method on DetectedConventions that returns a formatted string for LLM prompt injection (see Pattern 5 in RESEARCH.md). Include the CRITICAL warning about not hallucinating imports.

**detector.py:** Implement `detect_conventions(workspace_path: Path) -> DetectedConventions` with:

1. `detect_primary_language(workspace_path)` — count file extensions, exclude .git/node_modules/venv/__pycache__/dist/build/target directories. Map extensions to languages using LANGUAGE_EXTENSIONS dict from RESEARCH.md. Return "unknown" if no recognized files.

2. `find_and_parse_config(workspace_path, language)` — look for language-specific config files (pyproject.toml, setup.cfg, tox.ini for Python; package.json for JS/TS; go.mod for Go; Cargo.toml for Rust; composer.json for PHP). Parse with tomllib/json/configparser as appropriate. Return parsed dict or None.

3. `find_existing_tests(workspace_path, language)` — glob for test files using TEST_PATTERNS dict from RESEARCH.md. Exclude .git/node_modules/venv/__pycache__. Return up to 10 Path objects.

4. `detect_framework(config, test_files, language)` — check config for framework declarations first (pyproject.toml [tool.pytest], package.json devDependencies for jest/vitest, composer.json for phpunit), then fall back to scanning imports in first test file. Use RESEARCH.md Pattern 3 logic.

5. `infer_test_directory(test_files)` and `infer_naming_pattern(test_files, language)` — from RESEARCH.md Pattern 4.

Use structlog for logging (follow existing codebase pattern with `from booty.logging import get_logger`).

**__init__.py:** Export `detect_conventions`, `validate_test_imports`, `DetectedConventions`.
  </action>
  <verify>
    Run `python -c "from booty.test_generation import detect_conventions, DetectedConventions; print('OK')"` from project root.
    Run `python -c "from booty.test_generation.detector import detect_conventions; from pathlib import Path; result = detect_conventions(Path('.')); print(result.language, result.test_framework)"` — should detect Python and pytest for this repo.
  </verify>
  <done>
    DetectedConventions model exists with all fields and format_for_prompt() method.
    detect_conventions() returns correct results when pointed at the booty repo itself (language=python, test_framework=pytest or detected from pyproject.toml).
    All detection functions handle missing files/configs gracefully (return None, not crash).
  </done>
</task>

<task type="auto">
  <name>Task 2: Create import validator for anti-hallucination</name>
  <files>
    src/booty/test_generation/validator.py
  </files>
  <action>
Implement `validate_test_imports(test_file_content: str, language: str, workspace_path: Path) -> tuple[bool, list[str]]` following RESEARCH.md Pattern 6.

For Python validation (`validate_python_imports`):
1. Parse test content with `ast.parse()` — return syntax error if it fails
2. Extract all imports (both `import X` and `from X import Y`) — get root module name
3. Check each import against three sources:
   - `sys.stdlib_module_names` (Python 3.10+ stdlib set)
   - Project modules: scan `src/` and root for directories with `__init__.py` or `.py` files
   - Declared dependencies: parse `pyproject.toml` [project.dependencies] and [project.optional-dependencies], or `requirements.txt` — extract package names (strip version specifiers with regex `re.split(r"[><=!;\[]", dep)[0].strip()`)
4. Note: Python package names on PyPI often differ from import names (e.g., `Pillow` -> `PIL`, `python-dateutil` -> `dateutil`). Maintain a small COMMON_ALIASES dict for the most common mismatches. For unknown mappings, normalize both sides (lowercase, strip hyphens/underscores) and compare.
5. Any import not found in any source = potential hallucination, add to errors list
6. Return `(len(errors) == 0, errors)`

For non-Python languages: return `(True, [])` with a debug log "import validation not yet implemented for {language}". This is explicitly deferred per RESEARCH.md open question #5.

Use structlog for logging.
  </action>
  <verify>
    Run `python -c "from booty.test_generation.validator import validate_test_imports; from pathlib import Path; ok, errs = validate_test_imports('import os\nimport json\n', 'python', Path('.')); print(ok, errs)"` — should print `True []`.
    Run `python -c "from booty.test_generation.validator import validate_test_imports; from pathlib import Path; ok, errs = validate_test_imports('import fake_nonexistent_pkg\n', 'python', Path('.')); print(ok, errs)"` — should print `False` with error about fake_nonexistent_pkg.
  </verify>
  <done>
    validate_test_imports correctly identifies stdlib imports as valid.
    validate_test_imports correctly identifies project-internal imports as valid.
    validate_test_imports correctly identifies declared dependencies as valid.
    validate_test_imports flags unrecognized imports as potential hallucinations.
    validate_test_imports handles syntax errors gracefully.
    Non-Python languages return (True, []) without crashing.
  </done>
</task>

</tasks>

<verification>
- `python -c "from booty.test_generation import detect_conventions, validate_test_imports, DetectedConventions"` succeeds
- `python -c "from booty.test_generation.detector import detect_conventions; from pathlib import Path; r = detect_conventions(Path('.')); assert r.language == 'python', f'Got {r.language}'; print('Detection OK')"` passes
- `python -c "from booty.test_generation.validator import validate_test_imports; from pathlib import Path; ok, _ = validate_test_imports('import os\\nimport json', 'python', Path('.')); assert ok; print('Validation OK')"` passes
- No import errors, no circular dependencies
</verification>

<success_criteria>
- Convention detection module exists at src/booty/test_generation/
- DetectedConventions model has all required fields and format_for_prompt()
- detect_conventions() works on real repos (tested against booty itself)
- validate_test_imports() catches hallucinated imports
- All detection handles missing files/configs gracefully
</success_criteria>

<output>
After completion, create `.planning/phases/05-test-generation/05-01-SUMMARY.md`
</output>
